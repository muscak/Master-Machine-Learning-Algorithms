# Boosting

<img src='boosting.png' align='right' width=450 alt="Boosting">

Boosting is a general ensemble method that creates a strong classifier from a number of weak classifiers. This is done by building a model from the training data, then creating a second model that attempts to correct the errors from the first model. Models are added until the training set is predicted perfectly or a maximum number of models are added [1].

AdaBoost (Adaptive Boosting) was the first really successful boosting algorithm developed for binary classification. The most suited and therefore most common algorithm used with AdaBoost are decision trees with one level.

Overall, AdaBoost is a powerful and flexible algorithm that can be applied to a wide range of problems, and has been shown to be highly effective in practice.

## References

[1] [Master Machine Learning Algorithms](https://machinelearningmastery.com/master-machine-learning-algorithms/)
